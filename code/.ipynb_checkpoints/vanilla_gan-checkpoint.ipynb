{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Weâ€™ll use a simple GAN to generate frog images from the CIFAR dataset\n",
    "\n",
    "\n",
    "### The Dataset\n",
    "\n",
    "CIFAR has 10 image classes with 5,000 training images of dimension 32X32 in RGB.\n",
    "\n",
    "\n",
    "### Image Generation Program\n",
    "\n",
    "1. A generator network $G$ maps images of shape `(latent_dim,)` to `(32,32,3)` , so the generator map is $G: \\mathbb{R}\\rightarrow \\mathbb{R}^3$\n",
    "2. A discriminator network $D$ maps the images from `(32,32,3)`, to a binary score $`[0,1]` predicting whether the image is real or fake\n",
    "3.  A GAN network chains $D$ and $G$ so $GAN = D(G(x))$, so the GAN map is $G: \\mathbb{R} \\rightarrow \\mathbb{R}^3 \\rightarrow [0,1]$, from `(latent_dim,)` to `(32,32,3)` to `[0,1]`\n",
    "4. $D$ is trained with a collection of fake images (from $G$) and real images from the training set\n",
    "5. To train $G$, you adjust the weights in $G$ with regard to the loss of the $GAN$ model, so $G$ weights are updated in the directions that makes $D$ more likely classify fake images as real\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import relevant libs\n",
    "\n",
    "import tensorflow\n",
    "import keras\n",
    "#progress bar for keras\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 12682005189347036066, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11270533940\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "     link {\n",
       "       device_id: 1\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "   }\n",
       " }\n",
       " incarnation: 4471602824184595817\n",
       " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\", name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11285538407\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "     link {\n",
       "       type: \"StreamExecutor\"\n",
       "       strength: 1\n",
       "     }\n",
       "   }\n",
       " }\n",
       " incarnation: 14077058396035838503\n",
       " physical_device_desc: \"device: 1, name: Tesla K80, pci bus id: 0000:00:05.0, compute capability: 3.7\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if machine has GPU\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Generator \n",
    "\n",
    "\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "#latent vector\n",
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "\n",
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "#Transforms the generator input (latent_dim,) to a 16X16 128 channel feature map\n",
    "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((16, 16, 128))(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "#Transforms to 32 X 32\n",
    "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# These 3 lines produce a 32X32 1 channel image, which is the shape of CIFAR10 images\n",
    "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\\\n",
    "\n",
    "# Instantiates generator model which maps (latent_dim,) to (32,32,3)\n",
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 6, 6, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Discriminator\n",
    "\n",
    "\n",
    "discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "x = layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Flatten()(x)\n",
    "    \n",
    "# Trick 1: Dropout layer\n",
    "x = layers.Dropout(0.4)(x)\n",
    "# Classification step\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "# instantiates discriminator which turns (32,32,3) to [0,1]\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(\n",
    "        lr=0.0008,\n",
    "        clipvalue=1.0,\n",
    "        decay=1e-8)\n",
    "discriminator.compile(optimizer=discriminator_optimizer,loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial Network\n",
    "\n",
    "# This sets discriminator weights as untrainable\n",
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = keras.Input(shape=(latent_dim,)) \n",
    "\n",
    "gan_output = discriminator(generator(gan_input)) \n",
    "\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8) \n",
    "\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Algorithm Steps\n",
    "\n",
    "### Generate Data\n",
    "\n",
    "\n",
    "1. Create random latent space data (random noise in 1D vector) - shape `(latent_dim,)`\n",
    "2. Generate images from latent space date - shape `(32,32,3)`\n",
    "\n",
    "### Mix Fake + Real Data\n",
    "\n",
    "\n",
    "3. Mix real + fake images in one dataset (with targets real as 1 and fake as 0)\n",
    "\n",
    "### Train Discriminator\n",
    "\n",
    "\n",
    "4. Train discriminator with these images\n",
    "\n",
    "### Train Generator to Fool Discriminator\n",
    "\n",
    "\n",
    "5. Create new latent space random vectors\n",
    "6. Label them as real \n",
    "7. Train GAN with new random vectors (this step teaches G to fool D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the GAN algo\n",
    "\n",
    "import os\n",
    "from keras.preprocessing import image\n",
    "# load CIFAR data\n",
    "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select frogs\n",
    "x_train = x_train[y_train.flatten() == 6]\n",
    "\n",
    "# normalize data\n",
    "x_train = x_train.reshape(\n",
    "    (x_train.shape[0],) +\n",
    "    (height, width, channels)).astype('float32') / 255.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify where to save data, iteration, and batch size\n",
    "\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laskin_misha/.local/lib/python3.5/site-packages/keras/engine/training.py:478: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0\n",
      "discriminator loss: 0.7083238\n",
      "adversarial loss: 0.6945063\n",
      "step 100\n",
      "discriminator loss: 0.7151143\n",
      "adversarial loss: 0.7071212\n",
      "step 200\n",
      "discriminator loss: 0.7001738\n",
      "adversarial loss: 0.80984926\n",
      "step 300\n",
      "discriminator loss: 0.69444656\n",
      "adversarial loss: 0.77848965\n",
      "step 400\n",
      "discriminator loss: 0.69765127\n",
      "adversarial loss: 0.735351\n",
      "step 500\n",
      "discriminator loss: 0.6959867\n",
      "adversarial loss: 0.7793239\n",
      "step 600\n",
      "discriminator loss: 0.69855773\n",
      "adversarial loss: 0.7537593\n",
      "step 700\n",
      "discriminator loss: 0.69748765\n",
      "adversarial loss: 0.74746025\n",
      "step 800\n",
      "discriminator loss: 0.7836197\n",
      "adversarial loss: 0.78498536\n",
      "step 900\n",
      "discriminator loss: 0.68427706\n",
      "adversarial loss: 0.7280313\n",
      "step 1000\n",
      "discriminator loss: 0.6965578\n",
      "adversarial loss: 0.76312315\n",
      "step 1100\n",
      "discriminator loss: 0.6948187\n",
      "adversarial loss: 0.74227273\n",
      "step 1200\n",
      "discriminator loss: 0.68762124\n",
      "adversarial loss: 0.98710805\n",
      "step 1300\n",
      "discriminator loss: 0.6877942\n",
      "adversarial loss: 0.75625324\n",
      "step 1400\n",
      "discriminator loss: 0.73740304\n",
      "adversarial loss: 0.7615045\n",
      "step 1500\n",
      "discriminator loss: 0.69131136\n",
      "adversarial loss: 0.7704703\n",
      "step 1600\n",
      "discriminator loss: 0.6988849\n",
      "adversarial loss: 0.76226383\n",
      "step 1700\n",
      "discriminator loss: 0.6953661\n",
      "adversarial loss: 0.74072903\n",
      "step 1800\n",
      "discriminator loss: 0.7027321\n",
      "adversarial loss: 0.74280006\n",
      "step 1900\n",
      "discriminator loss: 0.6989432\n",
      "adversarial loss: 0.73942184\n",
      "step 2000\n",
      "discriminator loss: 0.69607365\n",
      "adversarial loss: 0.7629986\n",
      "step 2100\n",
      "discriminator loss: 0.69001734\n",
      "adversarial loss: 0.77026504\n",
      "step 2200\n",
      "discriminator loss: 0.70119786\n",
      "adversarial loss: 0.74394166\n",
      "step 2300\n",
      "discriminator loss: 0.7219265\n",
      "adversarial loss: 0.7329505\n",
      "step 2400\n",
      "discriminator loss: 0.68477285\n",
      "adversarial loss: 0.73803204\n",
      "step 2500\n",
      "discriminator loss: 0.68714637\n",
      "adversarial loss: 0.74608195\n",
      "step 2600\n",
      "discriminator loss: 0.6806037\n",
      "adversarial loss: 0.7395214\n",
      "step 2700\n",
      "discriminator loss: 0.8042162\n",
      "adversarial loss: 0.8012883\n",
      "step 2800\n",
      "discriminator loss: 0.68738425\n",
      "adversarial loss: 0.75358295\n",
      "step 2900\n",
      "discriminator loss: 0.69184077\n",
      "adversarial loss: 0.7853648\n",
      "step 3000\n",
      "discriminator loss: 0.69613236\n",
      "adversarial loss: 0.7450191\n",
      "step 3100\n",
      "discriminator loss: 0.69652534\n",
      "adversarial loss: 0.7408004\n",
      "step 3200\n",
      "discriminator loss: 0.72038364\n",
      "adversarial loss: 0.73274636\n",
      "step 3300\n",
      "discriminator loss: 0.694435\n",
      "adversarial loss: 0.6811093\n",
      "step 3400\n",
      "discriminator loss: 0.77077645\n",
      "adversarial loss: 0.7933043\n",
      "step 3500\n",
      "discriminator loss: 0.6720736\n",
      "adversarial loss: 0.92845315\n",
      "step 3600\n",
      "discriminator loss: 0.68069184\n",
      "adversarial loss: 0.75278395\n",
      "step 3700\n",
      "discriminator loss: 0.69070315\n",
      "adversarial loss: 0.78096735\n",
      "step 3800\n",
      "discriminator loss: 0.6948463\n",
      "adversarial loss: 0.7086207\n",
      "step 3900\n",
      "discriminator loss: 0.6750067\n",
      "adversarial loss: 0.73718166\n",
      "step 4000\n",
      "discriminator loss: 0.70305413\n",
      "adversarial loss: 0.761141\n",
      "step 4100\n",
      "discriminator loss: 0.71714437\n",
      "adversarial loss: 0.72861207\n",
      "step 4200\n",
      "discriminator loss: 0.6919397\n",
      "adversarial loss: 0.72911566\n",
      "step 4300\n",
      "discriminator loss: 0.68581337\n",
      "adversarial loss: 0.7678932\n",
      "step 4400\n",
      "discriminator loss: 0.7072829\n",
      "adversarial loss: 0.77009875\n",
      "step 4500\n",
      "discriminator loss: 0.69002455\n",
      "adversarial loss: 0.7381419\n",
      "step 4600\n",
      "discriminator loss: 0.70229375\n",
      "adversarial loss: 0.7522314\n",
      "step 4700\n",
      "discriminator loss: 0.6957089\n",
      "adversarial loss: 0.73975194\n",
      "step 4800\n",
      "discriminator loss: 0.6953757\n",
      "adversarial loss: 0.7627783\n",
      "step 4900\n",
      "discriminator loss: 0.68972033\n",
      "adversarial loss: 0.7385002\n",
      "step 5000\n",
      "discriminator loss: 0.69959986\n",
      "adversarial loss: 0.77088934\n",
      "step 5100\n",
      "discriminator loss: 0.69497067\n",
      "adversarial loss: 0.7447926\n",
      "step 5200\n",
      "discriminator loss: 0.7506026\n",
      "adversarial loss: 0.665157\n",
      "step 5300\n",
      "discriminator loss: 0.677806\n",
      "adversarial loss: 0.69862163\n",
      "step 5400\n",
      "discriminator loss: 0.68305427\n",
      "adversarial loss: 0.7530606\n",
      "step 5500\n",
      "discriminator loss: 0.70458543\n",
      "adversarial loss: 0.7474688\n",
      "step 5600\n",
      "discriminator loss: 0.68432957\n",
      "adversarial loss: 0.74212146\n",
      "step 5700\n",
      "discriminator loss: 0.7053442\n",
      "adversarial loss: 0.7593894\n",
      "step 5800\n",
      "discriminator loss: 0.6942297\n",
      "adversarial loss: 0.7431139\n",
      "step 5900\n",
      "discriminator loss: 0.69096404\n",
      "adversarial loss: 0.78992194\n",
      "step 6000\n",
      "discriminator loss: 0.6891726\n",
      "adversarial loss: 0.75010675\n",
      "step 6100\n",
      "discriminator loss: 0.69176066\n",
      "adversarial loss: 0.7041979\n",
      "step 6200\n",
      "discriminator loss: 0.6996497\n",
      "adversarial loss: 0.73004293\n",
      "step 6300\n",
      "discriminator loss: 0.79972637\n",
      "adversarial loss: 0.8050591\n",
      "step 6400\n",
      "discriminator loss: 0.7011253\n",
      "adversarial loss: 0.7800956\n",
      "step 6500\n",
      "discriminator loss: 0.67672336\n",
      "adversarial loss: 0.79947484\n",
      "step 6600\n",
      "discriminator loss: 0.70715094\n",
      "adversarial loss: 0.79325336\n",
      "step 6700\n",
      "discriminator loss: 0.69885576\n",
      "adversarial loss: 0.75220346\n",
      "step 6800\n",
      "discriminator loss: 0.69502926\n",
      "adversarial loss: 0.7164437\n",
      "step 6900\n",
      "discriminator loss: 0.6837972\n",
      "adversarial loss: 0.73633736\n",
      "step 7000\n",
      "discriminator loss: 0.71243924\n",
      "adversarial loss: 0.81648386\n",
      "step 7100\n",
      "discriminator loss: 0.6927186\n",
      "adversarial loss: 0.7695201\n",
      "step 7200\n",
      "discriminator loss: 0.69334096\n",
      "adversarial loss: 0.7953819\n",
      "step 7300\n",
      "discriminator loss: 0.7115568\n",
      "adversarial loss: 0.88409936\n",
      "step 7400\n",
      "discriminator loss: 0.6969081\n",
      "adversarial loss: 0.7968223\n",
      "step 7500\n",
      "discriminator loss: 0.69994766\n",
      "adversarial loss: 0.77122945\n",
      "step 7600\n",
      "discriminator loss: 0.7102359\n",
      "adversarial loss: 0.7809099\n",
      "step 7700\n",
      "discriminator loss: 0.70067465\n",
      "adversarial loss: 0.7775908\n",
      "step 7800\n",
      "discriminator loss: 0.69673276\n",
      "adversarial loss: 0.73712176\n",
      "step 7900\n",
      "discriminator loss: 0.7041353\n",
      "adversarial loss: 0.776256\n",
      "step 8000\n",
      "discriminator loss: 0.6815996\n",
      "adversarial loss: 0.7521702\n",
      "step 8100\n",
      "discriminator loss: 0.6816157\n",
      "adversarial loss: 0.8888729\n",
      "step 8200\n",
      "discriminator loss: 0.69442236\n",
      "adversarial loss: 0.8221146\n",
      "step 8300\n",
      "discriminator loss: 0.6840861\n",
      "adversarial loss: 0.7422659\n",
      "step 8400\n",
      "discriminator loss: 0.70667154\n",
      "adversarial loss: 0.7991251\n",
      "step 8500\n",
      "discriminator loss: 0.6591032\n",
      "adversarial loss: 0.8903178\n",
      "step 8600\n",
      "discriminator loss: 0.6925959\n",
      "adversarial loss: 0.78928363\n",
      "step 8700\n",
      "discriminator loss: 0.73597336\n",
      "adversarial loss: 0.83595026\n",
      "step 8800\n",
      "discriminator loss: 0.6675931\n",
      "adversarial loss: 0.8984256\n",
      "step 8900\n",
      "discriminator loss: 0.6825594\n",
      "adversarial loss: 0.76201814\n",
      "step 9000\n",
      "discriminator loss: 0.68997085\n",
      "adversarial loss: 0.75690913\n",
      "step 9100\n",
      "discriminator loss: 0.71073675\n",
      "adversarial loss: 0.8810817\n",
      "step 9200\n",
      "discriminator loss: 0.676816\n",
      "adversarial loss: 0.9452211\n",
      "step 9300\n",
      "discriminator loss: 0.69623595\n",
      "adversarial loss: 0.87187445\n",
      "step 9400\n",
      "discriminator loss: 0.6804172\n",
      "adversarial loss: 1.5615275\n",
      "step 9500\n",
      "discriminator loss: 0.676736\n",
      "adversarial loss: 0.79228866\n",
      "step 9600\n",
      "discriminator loss: 0.6674652\n",
      "adversarial loss: 0.73707974\n",
      "step 9700\n",
      "discriminator loss: 0.69466066\n",
      "adversarial loss: 0.70094216\n",
      "step 9800\n",
      "discriminator loss: 0.6701889\n",
      "adversarial loss: 0.83419144\n",
      "step 9900\n",
      "discriminator loss: 0.68498766\n",
      "adversarial loss: 0.80910647\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "\n",
    "for step in range(iterations):\n",
    "    \n",
    "    #create random latent space vectors\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size,\n",
    "                                        latent_dim))\n",
    "    \n",
    "    #convert vectors to images\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "    \n",
    "    #combine fake + real images\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start: stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    \n",
    "    #generate labels for fake / real images (true labels, no fooling here)\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "                         np.zeros((batch_size, 1))])\n",
    "    \n",
    "    #Trick: add random noise to labels\n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "    \n",
    "    #Train discriminator\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    \n",
    "    #create another batch of random latent space vectors\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size,latent_dim))\n",
    "    \n",
    "    #label these new vectors as real (this is a lie! this will be used to train G to fool D here)\n",
    "    misleading_targets = np.zeros((batch_size, 1))\n",
    "    \n",
    "    #trains G, recall that D's weights are frozen\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors,\n",
    "                            misleading_targets)\n",
    "    \n",
    "    #advance start position by batch_size\n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "        \n",
    "    #if step % 5 == 0:\n",
    "    #    print('step',step)\n",
    "    #save weights every 100 steps and plot image\n",
    "    if step % 100 == 0:\n",
    "        gan.save_weights('gan_gpu.h5')\n",
    "        \n",
    "        #print loss metrics\n",
    "        print('step',step)\n",
    "        print('discriminator loss:', d_loss)\n",
    "        print('adversarial loss:', a_loss)\n",
    "        \n",
    "        #save fake image\n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join('/home/laskin_misha/GANs/'+save_dir,'gpu_generated_frog' + str(step) + '.png'))\n",
    "        \n",
    "        #save real image\n",
    "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join('/home/laskin_misha/GANs/'+save_dir,'gpu_real_frog' + str(step) + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
